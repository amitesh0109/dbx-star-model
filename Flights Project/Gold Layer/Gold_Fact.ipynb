{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0304eb0e-d565-4fa4-819e-380b63385f67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0000d861-edb4-4093-a05e-1f665a89478d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Catalog Name\n",
    "catalog = \"workspace\"\n",
    "\n",
    "# Source Schema\n",
    "source_schema = \"silver\"\n",
    "\n",
    "# Source Object \n",
    "source_object = \"silver_bookings\"\n",
    "\n",
    "# CDC Column\n",
    "cdc_column = \"modifiedDate\"\n",
    "\n",
    "# Backdated Refresh\n",
    "backdated_refresh = \"\"\n",
    "\n",
    "# Source Fact Table\n",
    "fact_table = f\"{catalog}.{source_schema}.{source_object}\"\n",
    "\n",
    "# Target Schema \n",
    "target_schema = \"gold\"\n",
    "\n",
    "# Target Object \n",
    "target_object = \"FactBookings\"\n",
    "\n",
    "# Fact Key Cols List \n",
    "fact_key_cols = [\"DimPassengersKey\",\"DimFlightsKey\",\"DimAirportsKey\",\"booking_date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5928459d-a639-4cee-b1f0-bca1b9a248f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimPassengers\",\n",
    "        \"alias\": \"DimPassengers\",\n",
    "        \"join_keys\": [(\"passenger_id\", \"passenger_id\")]  # (fact_col, dim_col)\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimFlights\",\n",
    "        \"alias\": \"DimFlights\",\n",
    "        \"join_keys\": [(\"flight_id\", \"flight_id\")]  # (fact_col, dim_col)\n",
    "    },\n",
    "    {\n",
    "        \"table\": f\"{catalog}.{target_schema}.DimAirports\",\n",
    "        \"alias\": \"DimAirports\",\n",
    "        \"join_keys\": [(\"airport_id\", \"airport_id\")]  # (fact_col, dim_col)\n",
    "    },\n",
    "]\n",
    "\n",
    "'''\n",
    "Note : You can use the below code to add more dimensions to the fact table.\n",
    " \"join_keys\": [\n",
    "            (\"CountryID\", \"CountryID\"),\n",
    "            (\"RegionID\", \"RegionID\")\n",
    "        ]\n",
    "'''\n",
    "\n",
    "\n",
    "# Columns you want to keep from Fact table (besides the surrogate keys)\n",
    "fact_columns = [\"amount\",\"booking_date\",\"modifiedDate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "21896c97-99b9-4a1e-acb9-6c50b58d5e07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Get Last Load Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80b43d4e-cdf1-4578-b843-92d134b7882b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# No Back Dated Refresh\n",
    "if len(backdated_refresh) == 0:\n",
    "  \n",
    "  # If Table Exists In The Destination\n",
    "  if spark.catalog.tableExists(f\"{catalog}.{target_schema}.{target_object}\"):\n",
    "\n",
    "    last_load = spark.sql(f\"SELECT max({cdc_column}) FROM workspace.{target_schema}.{target_object}\").collect()[0][0]\n",
    "    \n",
    "  else:\n",
    "    last_load = \"1900-01-01 00:00:00\"\n",
    "\n",
    "# Yes Back Dated Refresh\n",
    "else:\n",
    "  last_load = backdated_refresh\n",
    "\n",
    "# Test The Last Load \n",
    "last_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7048998-d107-4b3e-9124-92157b7a0e87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dynamic Query (Fetch Fact Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "724a363f-f881-4fb5-91e5-10e69977ffe0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_fact_query_incremental(fact_table, dimensions, fact_columns, cdc_column, processing_date):\n",
    "    fact_alias = \"f\"\n",
    "    \n",
    "    # Base columns to select\n",
    "    select_cols = [f\"{fact_alias}.{col}\" for col in fact_columns]\n",
    "\n",
    "    # Build joins dynamically\n",
    "    join_clauses = []\n",
    "    for dim in dimensions:\n",
    "        table_full = dim[\"table\"]\n",
    "        alias = dim[\"alias\"]\n",
    "        table_name = table_full.split('.')[-1]\n",
    "        surrogate_key = f\"{alias}.{table_name}Key\"\n",
    "        select_cols.append(surrogate_key)\n",
    "\n",
    "        # Build ON clause\n",
    "        on_conditions = [\n",
    "            f\"{fact_alias}.{fk} = {alias}.{dk}\" for fk, dk in dim[\"join_keys\"]\n",
    "        ]\n",
    "        join_clause = f\"LEFT JOIN {table_full} {alias} ON \" + \" AND \".join(on_conditions)\n",
    "        join_clauses.append(join_clause)\n",
    "\n",
    "    # Final SELECT and JOIN clauses\n",
    "    select_clause = \",\\n    \".join(select_cols)\n",
    "    joins = \"\\n\".join(join_clauses)\n",
    "\n",
    "    # WHERE clause for incremental filtering\n",
    "    where_clause = f\"{fact_alias}.{cdc_column} >= DATE('{last_load}')\"\n",
    "\n",
    "    # Final query\n",
    "    query = f\"\"\"\n",
    "SELECT\n",
    "    {select_clause}\n",
    "FROM {fact_table} {fact_alias}\n",
    "{joins}\n",
    "WHERE {where_clause}\n",
    "\"\"\".strip()\n",
    "\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5506d21-b32d-49a5-8b8b-376d958351a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = generate_fact_query_incremental(fact_table, dimensions, fact_columns, cdc_column, last_load)\n",
    "\n",
    "df_fact = spark.sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c6456276-25f0-4371-80d4-2c92c2112049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Upsert Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ca664973-4d8a-4ede-8b94-404ce3b706e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Fact Key Columns Merge Condition\n",
    "fact_key_cols_str = \" AND \".join([f\"src.{col} = trg.{col}\" for col in fact_key_cols])\n",
    "fact_key_cols_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a247f38-0fb5-4429-89c8-18b78d5ff5e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from delta.tables import DeltaTable\n",
    "\n",
    "if spark.catalog.tableExists(f\"{catalog}.{target_schema}.{target_object}\"):\n",
    "\n",
    "    dlt_obj = DeltaTable.forName(spark, f\"{catalog}.{target_schema}.{target_object}\")\n",
    "    dlt_obj.alias(\"trg\").merge(df_fact.alias(\"src\"), fact_key_cols_str)\\\n",
    "                        .whenMatchedUpdateAll(condition = f\"src.{cdc_column} >= trg.{cdc_column}\")\\\n",
    "                        .whenNotMatchedInsertAll()\\\n",
    "                        .execute()\n",
    "\n",
    "else: \n",
    "\n",
    "    df_fact.write.format(\"delta\")\\\n",
    "            .mode(\"append\")\\\n",
    "            .saveAsTable(f\"{catalog}.{target_schema}.{target_object}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_Fact",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
